# 飞桨零基础入门深度学习笔记-day1

## 人工智能、机器学习、深度学习的关系

概括来说，人工智能、机器学习和深度学习覆盖的技术范畴是逐层递减的。人工智能是最宽泛的概念。机器学习是当前比较有效的一种实现人工智能的方式。深度学习是机器学习算法中最热门的一个分支，近些年取得了显著的进展，并替代了大多数传统机器学习算法。

人工智能 > 机器学习 > 深度学    如下图所示：

![](https://github.com/pangzhiwang/paddlepaddle/raw/master/images/image-20200812102909754.png)

## 机器学习

机器学习是专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构，使之不断改善自身的性能。

### 机器学习的实现

机器学习的实现可以分成两步：训练和预测，类似于我们熟悉的归纳和演绎：

- **归纳：** 从具体案例中抽象一般规律，机器学习中的“训练”亦是如此。从一定数量的样本（已知模型输入XX*X*和模型输出YY*Y*）中，学习输出YY*Y*与输入XX*X*的关系（可以想象成是某种表达式）。
- **演绎：** 从一般规律推导出具体案例的结果，机器学习中的“预测”亦是如此。基于训练得到的YY*Y*与XX*X*之间的关系，如出现新的输入XX*X*，计算出输出YY*Y*。通常情况下，如果通过模型计算的输出和真实场景的输出一致，则说明模型是有效的。

### 确定模型参数

下图是以HH*H*为模型的假设，它是一个关于参数WW*W*和输入XX*X*的函数，用H(W,X)H(W, X)*H*(*W*,*X*) 表示。模型的优化目标是H(W,X)H(W, X)*H*(*W*,*X*)的输出与真实输出YY*Y*尽量一致，两者的相差程度即是模型效果的评价函数（相差越小越好）。那么，确定参数的过程就是在已知的样本上，不断减小该评价函数（H(W,X)H(W, X)*H*(*W*,*X*) 和YY*Y*相差）的过程，直到学习到一个参数WW*W*，使得评价函数的取值最小。这个**衡量模型预测值和真实值差距的评价函数也被称为损失函数（损失Loss）**。

![image-20200812103304158](C:\Users\10856\AppData\Roaming\Typora\typora-user-images\image-20200812103304158.png)

### 模型结构介绍

成模型的三个部分：模型假设、评价函数和优化算法

构成模型的三个部分（模型假设、评价函数和优化算法）是如何支撑机器学习流程的？

![image-20200812103524569](C:\Users\10856\AppData\Roaming\Typora\typora-user-images\image-20200812103524569.png)

​	

- **模型假设**：世界上的可能关系千千万，漫无目标的试探Y~X之间的关系显然是十分低效的。因此假设空间先圈定了一个模型能够表达的关系可能，如蓝色圆圈所示。机器还会进一步在假设圈定的圆圈内寻找最优的Y~X关系，即确定参数W。
- **评价函数**：寻找最优之前，我们需要先定义什么是最优，即评价一个Y~X关系的好坏的指标。通常衡量该关系是否能很好的拟合现有观测样本，将拟合的误差最小作为优化目标。
- **优化算法**：设置了评价指标后，就可以在假设圈定的范围内，将使得评价指标最优（损失函数最小/最拟合已有观测样本）的Y~X关系找出来，这个寻找的方法即为优化算法。最笨的优化算法即按照参数的可能，穷举每一个可能取值来计算损失函数，保留使得损失函数最小的参数作为最终结果。

机器执行学习的框架体现了其**学习的本质是“参数估计”**（Learning is parameter estimation）。在此基础上，许多看起来完全不一样的问题都可以使用同样的框架进行学习，如科学定律、图像识别、机器翻译和自动问答等，它们的学习目标都是拟合一个“大公式”，如 下图 所示。

![image-20200812103823068](C:\Users\10856\AppData\Roaming\Typora\typora-user-images\image-20200812103823068.png)

## 深度学习

多数机器学习任务都可以使用深度学习模型解决，尤其在在语音、计算机视觉和自然语言处理等领域，深度学习模型的效果比传统机器学习算法有显著提升。

相比传统的机器学习算法，深度学习做出了哪些改进？

其实**两者在理论结构上是一致的，即：模型假设、评价函数和优化算法，其根本差别在于假设的复杂度**

### 神经网络的基本概念

人工神经网络包括多个神经网络层，如卷积层、全连接层、LSTM等，每一层又包括很多神经元，超过三层的非线性神经网络都可以被称为深度神经网络。通俗的讲，深度学习的模型可以视为是输入到输出的映射函数，如图像到高级语义（美女）的映射，足够深的神经网络理论上可以拟合任何复杂的函数。

神经网络结构如下图所示：

![image-20200812104542975](C:\Users\10856\AppData\Roaming\Typora\typora-user-images\image-20200812104542975.png)

- 神经元：神经网络中每个节点称为神经元，由两部分组成：

  - 加权和：将所有输入加权求和。
  - 非线性变换（激活函数）：加权和的结果经过一个非线性函数变换，让神经元计算具备非线性的能力。

- **多层连接：** 大量这样的节点按照不同的层次排布，形成多层的结构连接起来，即称为神经网络。

- **前向计算：** 从输入计算输出的过程，顺序从网络前至后。

- **计算图：** 以图形化的方式展现神经网络的计算逻辑又称为计算图。我们也可以将神经网络的计算图以公式的方式表达如下：

  Y=f3(f2(f1(w1⋅x1+w2⋅x2+w3⋅x3+b)+…)…)…)

由此可见，神经网络并没有那么神秘，它的本质是一个含有很多参数的“大公式”。
